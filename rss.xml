<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0"><channel><title>CV ArXiv Daily</title><link>https://tower02-hub.github.io/my_arXiv_daily/</link><description>Daily CV papers from ArXiv</description><language>en-us</language><lastBuildDate>Sat, 28 Jun 2025 01:19:42 GMT</lastBuildDate><item><title>Robust control for multi-legged elongate robots in noisy environments</title><link>http://arxiv.org/abs/2506.15788</link><pubDate>2025.06.18 00:00:00 GMT</pubDate><description>Baxi Chong et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.15788'&gt;http://arxiv.org/abs/2506.15788&lt;/a&gt;</description></item><item><title>Analog dual classifier via a time-modulated neuromorphic metasurface</title><link>http://arxiv.org/abs/2506.04629</link><pubDate>2025.06.05 00:00:00 GMT</pubDate><description>M. Mousa et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.04629'&gt;http://arxiv.org/abs/2506.04629&lt;/a&gt;</description></item><item><title>Zero-shot Sim-to-Real Transfer for Reinforcement Learning-based Visual Servoing of Soft Continuum Arms</title><link>http://arxiv.org/abs/2504.16916</link><pubDate>2025.04.23 00:00:00 GMT</pubDate><description>Hsin-Jung Yang et al. | Paper: &lt;a href='http://arxiv.org/abs/2504.16916'&gt;http://arxiv.org/abs/2504.16916&lt;/a&gt;</description></item><item><title>Coordinating Spinal and Limb Dynamics for Enhanced Sprawling Robot Mobility</title><link>http://arxiv.org/abs/2504.14103</link><pubDate>2025.04.18 00:00:00 GMT</pubDate><description>Merve Atasever et al. | Paper: &lt;a href='http://arxiv.org/abs/2504.14103'&gt;http://arxiv.org/abs/2504.14103&lt;/a&gt;</description></item><item><title>Mechanical Intelligence in Propulsion via Flexible Caudal Fins</title><link>http://arxiv.org/abs/2503.23652</link><pubDate>2025.03.31 00:00:00 GMT</pubDate><description>Sushrut Kumar et al. | Paper: &lt;a href='http://arxiv.org/abs/2503.23652'&gt;http://arxiv.org/abs/2503.23652&lt;/a&gt;</description></item><item><title>CS-SHAP: Extending SHAP to Cyclic-Spectral Domain for Better Interpretability of Intelligent Fault Diagnosis</title><link>http://arxiv.org/abs/2502.06424</link><pubDate>2025.02.10 00:00:00 GMT</pubDate><description>Qian Chen et al. | Paper: &lt;a href='http://arxiv.org/abs/2502.06424'&gt;http://arxiv.org/abs/2502.06424&lt;/a&gt;</description></item><item><title>Kiri-Spoon: A Kirigami Utensil for Robot-Assisted Feeding</title><link>http://arxiv.org/abs/2501.01323</link><pubDate>2025.01.02 00:00:00 GMT</pubDate><description>Maya Keely et al. | Paper: &lt;a href='http://arxiv.org/abs/2501.01323'&gt;http://arxiv.org/abs/2501.01323&lt;/a&gt; | Code: &lt;a href='https://github.com/vt-collab/kiri-spoon'&gt;https://github.com/vt-collab/kiri-spoon&lt;/a&gt;</description></item><item><title>Bridging Hard and Soft: Mechanical Metamaterials Enable Rigid Torque Transmission in Soft Robots</title><link>http://arxiv.org/abs/2412.02650</link><pubDate>2024.12.03 00:00:00 GMT</pubDate><description>Molly Carton et al. | Paper: &lt;a href='http://arxiv.org/abs/2412.02650'&gt;http://arxiv.org/abs/2412.02650&lt;/a&gt;</description></item><item><title>AquaMILR+: Design of an untethered limbless robot for complex aquatic terrain navigation</title><link>http://arxiv.org/abs/2409.18383</link><pubDate>2024.09.27 00:00:00 GMT</pubDate><description>Matthew Fernandez et al. | Paper: &lt;a href='http://arxiv.org/abs/2409.18383'&gt;http://arxiv.org/abs/2409.18383&lt;/a&gt;</description></item><item><title>A Neural Network-based Framework for Fast and Smooth Posture Reconstruction of a Soft Continuum Arm</title><link>http://arxiv.org/abs/2409.12443</link><pubDate>2024.09.19 00:00:00 GMT</pubDate><description>Tixian Wang et al. | Paper: &lt;a href='http://arxiv.org/abs/2409.12443'&gt;http://arxiv.org/abs/2409.12443&lt;/a&gt;</description></item><item><title>Multi-robot connective collaboration toward collective obstacle field traversal</title><link>http://arxiv.org/abs/2409.11709</link><pubDate>2025.02.03 00:00:00 GMT</pubDate><description>Haodi Hu et al. | Paper: &lt;a href='http://arxiv.org/abs/2409.11709'&gt;http://arxiv.org/abs/2409.11709&lt;/a&gt;</description></item><item><title>Persistent pseudopod splitting is an effective chemotaxis strategy in shallow gradients</title><link>http://arxiv.org/abs/2409.09342</link><pubDate>2024.10.26 00:00:00 GMT</pubDate><description>Albert Alonso et al. | Paper: &lt;a href='http://arxiv.org/abs/2409.09342'&gt;http://arxiv.org/abs/2409.09342&lt;/a&gt; | Code: &lt;a href='https://github.com/Endres-group/psxc-research'&gt;https://github.com/Endres-group/psxc-research&lt;/a&gt;</description></item><item><title>Minimal actuation and control of a soft hydrogel swimmer from flutter instability</title><link>http://arxiv.org/abs/2408.02560</link><pubDate>2024.08.05 00:00:00 GMT</pubDate><description>Ariel Surya Boiardi et al. | Paper: &lt;a href='http://arxiv.org/abs/2408.02560'&gt;http://arxiv.org/abs/2408.02560&lt;/a&gt;</description></item><item><title>Embodying Control in Soft Multistable Robots from Morphofunctional Co-design</title><link>http://arxiv.org/abs/2407.08111</link><pubDate>2025.05.12 00:00:00 GMT</pubDate><description>Juan C. Osorio et al. | Paper: &lt;a href='http://arxiv.org/abs/2407.08111'&gt;http://arxiv.org/abs/2407.08111&lt;/a&gt;</description></item><item><title>AquaMILR: Mechanical intelligence simplifies control of undulatory robots in cluttered fluid environments</title><link>http://arxiv.org/abs/2407.01733</link><pubDate>2024.09.27 00:00:00 GMT</pubDate><description>Tianyu Wang et al. | Paper: &lt;a href='http://arxiv.org/abs/2407.01733'&gt;http://arxiv.org/abs/2407.01733&lt;/a&gt;</description></item><item><title>Evolutionary Morphology Towards Overconstrained Locomotion via Large-Scale, Multi-Terrain Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2407.01050</link><pubDate>2024.07.01 00:00:00 GMT</pubDate><description>Yenan Chen et al. | Paper: &lt;a href='http://arxiv.org/abs/2407.01050'&gt;http://arxiv.org/abs/2407.01050&lt;/a&gt;</description></item><item><title>Intelligence as Computation</title><link>http://arxiv.org/abs/2405.16604</link><pubDate>2024.05.26 00:00:00 GMT</pubDate><description>Oliver Brock et al. | Paper: &lt;a href='http://arxiv.org/abs/2405.16604'&gt;http://arxiv.org/abs/2405.16604&lt;/a&gt;</description></item><item><title>MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm System</title><link>http://arxiv.org/abs/2403.19992</link><pubDate>2024.10.19 00:00:00 GMT</pubDate><description>Maha Nawaz et al. | Paper: &lt;a href='http://arxiv.org/abs/2403.19992'&gt;http://arxiv.org/abs/2403.19992&lt;/a&gt;</description></item><item><title>Study of Workload Interference with Intelligent Routing on Dragonfly</title><link>http://arxiv.org/abs/2403.16288</link><pubDate>2024.04.03 00:00:00 GMT</pubDate><description>Yao Kang et al. | Paper: &lt;a href='http://arxiv.org/abs/2403.16288'&gt;http://arxiv.org/abs/2403.16288&lt;/a&gt;</description></item><item><title>Development and Characteristics of a Highly Biomimetic Robotic Shoulder Through Bionics-Inspired Optimization</title><link>http://arxiv.org/abs/2310.18283</link><pubDate>2023.10.27 00:00:00 GMT</pubDate><description>Haosen Yang et al. | Paper: &lt;a href='http://arxiv.org/abs/2310.18283'&gt;http://arxiv.org/abs/2310.18283&lt;/a&gt;</description></item><item><title>Anisotropic body compliance facilitates robotic sidewinding in complex environments</title><link>http://arxiv.org/abs/2309.13532</link><pubDate>2023.09.24 00:00:00 GMT</pubDate><description>Velin Kojouharov et al. | Paper: &lt;a href='http://arxiv.org/abs/2309.13532'&gt;http://arxiv.org/abs/2309.13532&lt;/a&gt;</description></item><item><title>Mechanical intelligence via fully reconfigurable elastic neuromorphic metasurfaces</title><link>http://arxiv.org/abs/2308.04002</link><pubDate>2024.05.09 00:00:00 GMT</pubDate><description>M. Moghaddaszadeh et al. | Paper: &lt;a href='http://arxiv.org/abs/2308.04002'&gt;http://arxiv.org/abs/2308.04002&lt;/a&gt;</description></item><item><title>Uncovering multifunctional mechano-intelligence in and through phononic metastructures harnessing physical reservoir computing</title><link>http://arxiv.org/abs/2305.19354</link><pubDate>2023.05.30 00:00:00 GMT</pubDate><description>Yuning Zhang et al. | Paper: &lt;a href='http://arxiv.org/abs/2305.19354'&gt;http://arxiv.org/abs/2305.19354&lt;/a&gt;</description></item><item><title>Mechanical Intelligence Simplifies Control in Terrestrial Limbless Locomotion</title><link>http://arxiv.org/abs/2304.08652</link><pubDate>2024.02.01 00:00:00 GMT</pubDate><description>Tianyu Wang et al. | Paper: &lt;a href='http://arxiv.org/abs/2304.08652'&gt;http://arxiv.org/abs/2304.08652&lt;/a&gt;</description></item><item><title>Neuromechanical Autoencoders: Learning to Couple Elastic and Neural Network Nonlinearity</title><link>http://arxiv.org/abs/2302.00032</link><pubDate>2023.01.31 00:00:00 GMT</pubDate><description>Deniz Oktay et al. | Paper: &lt;a href='http://arxiv.org/abs/2302.00032'&gt;http://arxiv.org/abs/2302.00032&lt;/a&gt;</description></item><item><title>Aerobat, A Bioinspired Drone to Test High-DOF Actuation and Embodied Aerial Locomotion</title><link>http://arxiv.org/abs/2212.05361</link><pubDate>2022.12.10 00:00:00 GMT</pubDate><description>Alireza Ramezani et al. | Paper: &lt;a href='http://arxiv.org/abs/2212.05361'&gt;http://arxiv.org/abs/2212.05361&lt;/a&gt;</description></item><item><title>A Vision Transformer-Based Approach to Bearing Fault Classification via Vibration Signals</title><link>http://arxiv.org/abs/2208.07070</link><pubDate>2022.09.20 00:00:00 GMT</pubDate><description>Abid Hasan Zim et al. | Paper: &lt;a href='http://arxiv.org/abs/2208.07070'&gt;http://arxiv.org/abs/2208.07070&lt;/a&gt;</description></item><item><title>Power to the springs: Passive elements are sufficient to drive push-off in human walking</title><link>http://arxiv.org/abs/2205.00871</link><pubDate>2022.04.29 00:00:00 GMT</pubDate><description>Alexandra Buchmann et al. | Paper: &lt;a href='http://arxiv.org/abs/2205.00871'&gt;http://arxiv.org/abs/2205.00871&lt;/a&gt;</description></item><item><title>Visual Servoing for Pose Control of Soft Continuum Arm in a Structured Environment</title><link>http://arxiv.org/abs/2202.05200</link><pubDate>2022.03.12 00:00:00 GMT</pubDate><description>Shivani Kamtikar et al. | Paper: &lt;a href='http://arxiv.org/abs/2202.05200'&gt;http://arxiv.org/abs/2202.05200&lt;/a&gt;</description></item><item><title>Soft Robots Learn to Crawl: Jointly Optimizing Design and Control with Sim-to-Real Transfer</title><link>http://arxiv.org/abs/2202.04575</link><pubDate>2022.02.09 00:00:00 GMT</pubDate><description>Charles Schaff et al. | Paper: &lt;a href='http://arxiv.org/abs/2202.04575'&gt;http://arxiv.org/abs/2202.04575&lt;/a&gt;</description></item><item><title>Whole-Body Conditioned Egocentric Video Prediction</title><link>http://arxiv.org/abs/2506.21552</link><pubDate>2025.06.26 00:00:00 GMT</pubDate><description>Yutong Bai et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.21552'&gt;http://arxiv.org/abs/2506.21552&lt;/a&gt;</description></item><item><title>ACTLLM: Action Consistency Tuned Large Language Model</title><link>http://arxiv.org/abs/2506.21250</link><pubDate>2025.06.26 00:00:00 GMT</pubDate><description>Jing Bi et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.21250'&gt;http://arxiv.org/abs/2506.21250&lt;/a&gt;</description></item><item><title>World-aware Planning Narratives Enhance Large Vision-Language Model Planner</title><link>http://arxiv.org/abs/2506.21230</link><pubDate>2025.06.26 00:00:00 GMT</pubDate><description>Junhao Shi et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.21230'&gt;http://arxiv.org/abs/2506.21230&lt;/a&gt;</description></item><item><title>UAIbot: Beginner-friendly web-based simulator for interactive robotics learning and research</title><link>http://arxiv.org/abs/2506.21178</link><pubDate>2025.06.26 00:00:00 GMT</pubDate><description>Johnata Brayan et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.21178'&gt;http://arxiv.org/abs/2506.21178&lt;/a&gt;</description></item><item><title>Knowledge-Driven Imitation Learning: Enabling Generalization Across Diverse Conditions</title><link>http://arxiv.org/abs/2506.21057</link><pubDate>2025.06.26 00:00:00 GMT</pubDate><description>Zhuochen Miao et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.21057'&gt;http://arxiv.org/abs/2506.21057&lt;/a&gt;</description></item><item><title>Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends</title><link>http://arxiv.org/abs/2506.20966</link><pubDate>2025.06.26 00:00:00 GMT</pubDate><description>Tian-Yu Xiang et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.20966'&gt;http://arxiv.org/abs/2506.20966&lt;/a&gt;</description></item><item><title>Learning-Based Distance Estimation for 360° Single-Sensor Setups</title><link>http://arxiv.org/abs/2506.20586</link><pubDate>2025.06.25 00:00:00 GMT</pubDate><description>Yitong Quan et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.20586'&gt;http://arxiv.org/abs/2506.20586&lt;/a&gt;</description></item><item><title>Learn to Position -- A Novel Meta Method for Robotic Positioning</title><link>http://arxiv.org/abs/2506.20445</link><pubDate>2025.06.25 00:00:00 GMT</pubDate><description>Dongkun Wang et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.20445'&gt;http://arxiv.org/abs/2506.20445&lt;/a&gt;</description></item><item><title>Enhanced Robotic Navigation in Deformable Environments using Learning from Demonstration and Dynamic Modulation</title><link>http://arxiv.org/abs/2506.20376</link><pubDate>2025.06.25 00:00:00 GMT</pubDate><description>Lingyun Chen et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.20376'&gt;http://arxiv.org/abs/2506.20376&lt;/a&gt;</description></item><item><title>Finding the Easy Way Through -- the Probabilistic Gap Planner for Social Robot Navigation</title><link>http://arxiv.org/abs/2506.20320</link><pubDate>2025.06.26 00:00:00 GMT</pubDate><description>Malte Probst et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.20320'&gt;http://arxiv.org/abs/2506.20320&lt;/a&gt;</description></item><item><title>Building Forest Inventories with Autonomous Legged Robots -- System, Lessons, and Challenges Ahead</title><link>http://arxiv.org/abs/2506.20315</link><pubDate>2025.06.25 00:00:00 GMT</pubDate><description>Matías Mattamala et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.20315'&gt;http://arxiv.org/abs/2506.20315&lt;/a&gt;</description></item><item><title>Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration</title><link>http://arxiv.org/abs/2506.20307</link><pubDate>2025.06.25 00:00:00 GMT</pubDate><description>Heyang Zhao et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.20307'&gt;http://arxiv.org/abs/2506.20307&lt;/a&gt;</description></item><item><title>Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception</title><link>http://arxiv.org/abs/2506.20045</link><pubDate>2025.06.26 00:00:00 GMT</pubDate><description>Eric C. Joyce et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.20045'&gt;http://arxiv.org/abs/2506.20045&lt;/a&gt;</description></item><item><title>Unified Vision-Language-Action Model</title><link>http://arxiv.org/abs/2506.19850</link><pubDate>2025.06.24 00:00:00 GMT</pubDate><description>Yuqi Wang et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19850'&gt;http://arxiv.org/abs/2506.19850&lt;/a&gt;</description></item><item><title>Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI</title><link>http://arxiv.org/abs/2506.19613</link><pubDate>2025.06.24 00:00:00 GMT</pubDate><description>Sha Zhang et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19613'&gt;http://arxiv.org/abs/2506.19613&lt;/a&gt;</description></item><item><title>Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects</title><link>http://arxiv.org/abs/2506.19579</link><pubDate>2025.06.24 00:00:00 GMT</pubDate><description>Federico Tavella et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19579'&gt;http://arxiv.org/abs/2506.19579&lt;/a&gt;</description></item><item><title>T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic Manipulation with Vision-Language Models</title><link>http://arxiv.org/abs/2506.19498</link><pubDate>2025.06.24 00:00:00 GMT</pubDate><description>Yiteng Chen et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19498'&gt;http://arxiv.org/abs/2506.19498&lt;/a&gt;</description></item><item><title>Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System</title><link>http://arxiv.org/abs/2506.19433</link><pubDate>2025.06.24 00:00:00 GMT</pubDate><description>Lixuan He et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19433'&gt;http://arxiv.org/abs/2506.19433&lt;/a&gt;</description></item><item><title>Is an object-centric representation beneficial for robotic manipulation ?</title><link>http://arxiv.org/abs/2506.19408</link><pubDate>2025.06.24 00:00:00 GMT</pubDate><description>Alexandre Chapin et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19408'&gt;http://arxiv.org/abs/2506.19408&lt;/a&gt;</description></item><item><title>Robotic Perception with a Large Tactile-Vision-Language Model for Physical Property Inference</title><link>http://arxiv.org/abs/2506.19303</link><pubDate>2025.06.24 00:00:00 GMT</pubDate><description>Zexiang Guo et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19303'&gt;http://arxiv.org/abs/2506.19303&lt;/a&gt;</description></item><item><title>AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation</title><link>http://arxiv.org/abs/2506.19269</link><pubDate>2025.06.25 00:00:00 GMT</pubDate><description>Ziyan Zhao et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19269'&gt;http://arxiv.org/abs/2506.19269&lt;/a&gt;</description></item><item><title>Robust Behavior Cloning Via Global Lipschitz Regularization</title><link>http://arxiv.org/abs/2506.19250</link><pubDate>2025.06.24 00:00:00 GMT</pubDate><description>Shili Wu et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19250'&gt;http://arxiv.org/abs/2506.19250&lt;/a&gt;</description></item><item><title>CUPID: Curating Data your Robot Loves with Influence Functions</title><link>http://arxiv.org/abs/2506.19121</link><pubDate>2025.06.23 00:00:00 GMT</pubDate><description>Christopher Agia et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19121'&gt;http://arxiv.org/abs/2506.19121&lt;/a&gt;</description></item><item><title>Multimodal Anomaly Detection with a Mixture-of-Experts</title><link>http://arxiv.org/abs/2506.19077</link><pubDate>2025.06.23 00:00:00 GMT</pubDate><description>Christoph Willibald et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.19077'&gt;http://arxiv.org/abs/2506.19077&lt;/a&gt;</description></item><item><title>FORTE: Tactile Force and Slip Sensing on Compliant Fingers for Delicate Manipulation</title><link>http://arxiv.org/abs/2506.18960</link><pubDate>2025.06.25 00:00:00 GMT</pubDate><description>Siqi Shang et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.18960'&gt;http://arxiv.org/abs/2506.18960&lt;/a&gt;</description></item><item><title>RAG-6DPose: Retrieval-Augmented 6D Pose Estimation via Leveraging CAD as Knowledge Base</title><link>http://arxiv.org/abs/2506.18856</link><pubDate>2025.06.23 00:00:00 GMT</pubDate><description>Kuanning Wang et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.18856'&gt;http://arxiv.org/abs/2506.18856&lt;/a&gt;</description></item><item><title>SViP: Sequencing Bimanual Visuomotor Policies with Object-Centric Motion Primitives</title><link>http://arxiv.org/abs/2506.18825</link><pubDate>2025.06.23 00:00:00 GMT</pubDate><description>Yizhou Chen et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.18825'&gt;http://arxiv.org/abs/2506.18825&lt;/a&gt;</description></item><item><title>Learning Point Correspondences In Radar 3D Point Clouds For Radar-Inertial Odometry</title><link>http://arxiv.org/abs/2506.18580</link><pubDate>2025.06.23 00:00:00 GMT</pubDate><description>Jan Michalczyk et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.18580'&gt;http://arxiv.org/abs/2506.18580&lt;/a&gt;</description></item><item><title>AViLA: Asynchronous Vision-Language Agent for Streaming Multimodal Data Interaction</title><link>http://arxiv.org/abs/2506.18472</link><pubDate>2025.06.23 00:00:00 GMT</pubDate><description>Gengyuan Zhang et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.18472'&gt;http://arxiv.org/abs/2506.18472&lt;/a&gt;</description></item><item><title>Robots and Children that Learn Together : Improving Knowledge Retention by Teaching Peer-Like Interactive Robots</title><link>http://arxiv.org/abs/2506.18365</link><pubDate>2025.06.23 00:00:00 GMT</pubDate><description>Imene Tarakli et al. | Paper: &lt;a href='http://arxiv.org/abs/2506.18365'&gt;http://arxiv.org/abs/2506.18365&lt;/a&gt;</description></item></channel></rss>